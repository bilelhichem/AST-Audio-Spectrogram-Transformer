{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612382c8",
   "metadata": {},
   "source": [
    "### Lister tous les fichiers audio avec leurs labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bb0478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "genres = sorted(os.listdir(\"../Data/genres_original\"))  \n",
    "\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for idx , genre in enumerate(genres):\n",
    "    files = glob.glob(f\"../Data/genres_original/{genre}/*.wav\")\n",
    "    for f in files :\n",
    "        filepaths.append(f)\n",
    "        labels.append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44965f72",
   "metadata": {},
   "source": [
    "### Découper en train / val / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "355eb356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 train\n",
      "151 val\n",
      "150 test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    filepaths, labels, test_size=0.15, random_state=42, stratify=labels)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp)\n",
    " \n",
    "\n",
    "print(len(X_train), \"train\")\n",
    "print(len(X_val),   \"val\")\n",
    "print(len(X_test),  \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8720c6",
   "metadata": {},
   "source": [
    "### découper les fichiers en segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72fc2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import audioread  # force fallback\n",
    "\n",
    "def split_audio(file, segment_duration=3, sr=22050):\n",
    "    try:\n",
    "        signal, _ = librosa.load(file, sr=sr)\n",
    "    except Exception as e:\n",
    "        print(\"Erreur sur:\", file, e)\n",
    "        return []  # ignorer le fichier problématique\n",
    "\n",
    "    samples_per_segment = sr * segment_duration\n",
    "    segments = []\n",
    "\n",
    "    for start in range(0, len(signal), samples_per_segment):\n",
    "        end = start + samples_per_segment\n",
    "        part = signal[start:end]\n",
    "        if len(part) == samples_per_segment:\n",
    "            segments.append(part)\n",
    "\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e458af",
   "metadata": {},
   "source": [
    "### Appliquer la découpe à train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0436090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/r64x99yx2k91vgyysnwnb7pc0000gn/T/ipykernel_4939/2648669402.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, _ = librosa.load(file, sr=sr)\n",
      "/Users/mac/Desktop/Ast_Projet/.venv/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur sur: ../Data/genres_original/jazz/jazz.00054.wav \n",
      "Train segments: 6977\n"
     ]
    }
   ],
   "source": [
    "X_train_segments = []\n",
    "y_train_segments = []\n",
    "\n",
    "for idx, file in enumerate(X_train):\n",
    "    segs = split_audio(file)\n",
    "    X_train_segments.extend(segs)\n",
    "    y_train_segments.extend([y_train[idx]] * len(segs))\n",
    "\n",
    "print(\"Train segments:\", len(X_train_segments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccce133",
   "metadata": {},
   "source": [
    "### Appliquer la découpe à test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6d22521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test segments: 1495\n"
     ]
    }
   ],
   "source": [
    "X_test_segments = []\n",
    "y_test_segments = []\n",
    "\n",
    "for idx, file in enumerate(X_test):\n",
    "    segs = split_audio(file)\n",
    "    X_test_segments.extend(segs)\n",
    "    y_test_segments.extend([y_test[idx]] * len(segs))\n",
    "\n",
    "print(\"Test segments:\", len(X_test_segments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca109475",
   "metadata": {},
   "source": [
    "### Appliquer la découpe à val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c981729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val segments: 1509\n"
     ]
    }
   ],
   "source": [
    "X_val_segments = []\n",
    "y_val_segments = []\n",
    "\n",
    "for idx, file in enumerate(X_val):\n",
    "    segs = split_audio(file)\n",
    "    X_val_segments.extend(segs)\n",
    "    y_val_segments.extend([y_val[idx]] * len(segs))\n",
    "\n",
    "print(\"Val segments:\", len(X_val_segments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777633b6",
   "metadata": {},
   "source": [
    "### convertir un segment → log-mel spectrogram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
