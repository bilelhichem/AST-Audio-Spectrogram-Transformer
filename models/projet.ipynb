{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLwyXDyoMlWt",
        "outputId": "23f42a80-f83c-488a-bd55-26393c228168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VjWEMmotIfW9"
      },
      "outputs": [],
      "source": [
        "\n",
        "base_path = \"/content/drive/MyDrive/genres_original\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EiA2W17CJddi"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "genres = sorted(os.listdir(base_path))\n",
        "\n",
        "\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "for idx , genre in enumerate(genres):\n",
        "    files = glob.glob(f\"{base_path}/{genre}/*.wav\")\n",
        "    for f in files :\n",
        "        filepaths.append(f)\n",
        "        labels.append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW36PGa6KAQJ",
        "outputId": "dfe03e97-c0e9-4f39-f5f7-18b6baf5ad50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "699 train\n",
            "151 val\n",
            "150 test\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    filepaths, labels, test_size=0.15, random_state=42, stratify=labels)\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp)\n",
        "\n",
        "\n",
        "print(len(X_train), \"train\")\n",
        "print(len(X_val),   \"val\")\n",
        "print(len(X_test),  \"test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u3rQTOWDKBK5"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import audioread  # force fallback\n",
        "\n",
        "def split_audio(file, segment_duration=3, sr=22050):\n",
        "    try:\n",
        "        signal, _ = librosa.load(file, sr=sr)\n",
        "    except Exception as e:\n",
        "        print(\"Erreur sur:\", file, e)\n",
        "        return []  # ignorer le fichier problématique\n",
        "\n",
        "    samples_per_segment = sr * segment_duration\n",
        "    segments = []\n",
        "\n",
        "    for start in range(0, len(signal), samples_per_segment):\n",
        "        end = start + samples_per_segment\n",
        "        part = signal[start:end]\n",
        "        if len(part) == samples_per_segment:\n",
        "            segments.append(part)\n",
        "\n",
        "    return segments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxJ3mZ_UKCsU",
        "outputId": "6048d229-68db-400b-a879-fde88be58122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train segments: 6986\n"
          ]
        }
      ],
      "source": [
        "X_train_segments = []\n",
        "y_train_segments = []\n",
        "\n",
        "for idx, file in enumerate(X_train):\n",
        "    segs = split_audio(file)\n",
        "    X_train_segments.extend(segs)\n",
        "    y_train_segments.extend([y_train[idx]] * len(segs))\n",
        "\n",
        "print(\"Train segments:\", len(X_train_segments))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njb1jTC1KEY6",
        "outputId": "7634b898-668a-41b6-8bc5-8f48a2a09d43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2648669402.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, _ = librosa.load(file, sr=sr)\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Erreur sur: /content/drive/MyDrive/genres_original/jazz/jazz.00054.wav \n",
            "Test segments: 1489\n"
          ]
        }
      ],
      "source": [
        "X_test_segments = []\n",
        "y_test_segments = []\n",
        "\n",
        "for idx, file in enumerate(X_test):\n",
        "    segs = split_audio(file)\n",
        "    X_test_segments.extend(segs)\n",
        "    y_test_segments.extend([y_test[idx]] * len(segs))\n",
        "\n",
        "print(\"Test segments:\", len(X_test_segments))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfRkBtpmKG7o",
        "outputId": "fb1c1a32-204f-4757-a8e1-6f26087fef36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val segments: 1506\n"
          ]
        }
      ],
      "source": [
        "X_val_segments = []\n",
        "y_val_segments = []\n",
        "\n",
        "for idx, file in enumerate(X_val):\n",
        "    segs = split_audio(file)\n",
        "    X_val_segments.extend(segs)\n",
        "    y_val_segments.extend([y_val[idx]] * len(segs))\n",
        "\n",
        "print(\"Val segments:\", len(X_val_segments))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O4McrEejKIa-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def segment_to_logmel(segment, sr=22050, n_mels=128, n_fft=1024, hop_length=512):\n",
        "    # Mel spectrogram\n",
        "    mel_spec = librosa.feature.melspectrogram(\n",
        "        y=segment,\n",
        "        sr=sr,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        n_mels=n_mels\n",
        "    )\n",
        "\n",
        "    # Log-mel\n",
        "    log_mel = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    # Normalisation\n",
        "    log_mel_norm = (log_mel - log_mel.min()) / (log_mel.max() - log_mel.min())\n",
        "\n",
        "    # Ajustement de la largeur à 128\n",
        "    log_mel_norm = librosa.util.fix_length(log_mel_norm, size=128, axis=1)\n",
        "\n",
        "    return log_mel_norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UPngtnN-KJgt"
      },
      "outputs": [],
      "source": [
        "X_train_mel = [segment_to_logmel(seg) for seg in X_train_segments]\n",
        "X_val_mel  = [segment_to_logmel(seg) for seg in X_val_segments]\n",
        "X_test_mel = [segment_to_logmel(seg) for seg in X_test_segments]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yKa3gqjwKLab"
      },
      "outputs": [],
      "source": [
        "X_train_mel = np.array(X_train_mel)\n",
        "X_val_mel   = np.array(X_val_mel)\n",
        "X_test_mel  = np.array(X_test_mel)\n",
        "\n",
        "y_train_segments = np.array(y_train_segments)\n",
        "y_val_segments   = np.array(y_val_segments)\n",
        "y_test_segments  = np.array(y_test_segments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q21o_8dnKM0-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GTZANDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        # X : numpy array des log-mels\n",
        "        # y : numpy array des labels\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)  # convertir en tensor float\n",
        "        self.y = torch.tensor(y, dtype=torch.long)     # labels int\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3hmLNyMZKOX2"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = GTZANDataset(X_train_mel, y_train_segments)\n",
        "val_dataset   = GTZANDataset(X_val_mel, y_val_segments)\n",
        "test_dataset  = GTZANDataset(X_test_mel, y_test_segments)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8lxsK9qsu_B",
        "outputId": "2169f0d1-8618-4f24-f3b3-0d2c057b13bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.12/dist-packages (3.2)\n",
            "Requirement already satisfied: timm==0.4.5 in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.12/dist-packages (from timm==0.4.5) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==0.4.5) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.5) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm==0.4.5) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm==0.4.5) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4->timm==0.4.5) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.4->timm==0.4.5) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install timm==0.4.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uvO4c0lGuxgI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# chemin réel de tes poids\n",
        "real_pretrained_dir = \"/content/drive/MyDrive/ast/pretrained_models\"\n",
        "\n",
        "# créer un lien symbolique vers le chemin attendu par AST\n",
        "!mkdir -p /content/../../  # assure que le dossier parent existe\n",
        "!ln -sfn \"{real_pretrained_dir}\" /content/../../pretrained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MarmCPju_Ig",
        "outputId": "e8367e4a-5ff1-4c09-ba4b-669f7ecb0def"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ast/src/models/ast_models.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------AST Model Summary---------------\n",
            "ImageNet pretraining: True, AudioSet pretraining: True\n",
            "frequncey stride=10, time stride=10\n",
            "number of patches=144\n",
            "ASTModel(\n",
            "  (v): DistilledVisionTransformer(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "    (blocks): ModuleList(\n",
            "      (0-11): 12 x Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (pre_logits): Identity()\n",
            "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            "    (head_dist): Linear(in_features=768, out_features=1000, bias=True)\n",
            "  )\n",
            "  (mlp_head): Sequential(\n",
            "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=768, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/ast/src/models\")\n",
        "\n",
        "from ast_models import ASTModel\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = ASTModel(\n",
        "    label_dim=num_classes,\n",
        "    input_fdim=128,\n",
        "    input_tdim=128,\n",
        "    imagenet_pretrain=True,\n",
        "    audioset_pretrain=True\n",
        ")\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hRX_sFgjK13F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCidZYOiK3NM",
        "outputId": "d6db3dcb-a8a5-4c73-ae4f-448c299a9886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 1.0772\n",
            "Epoch 2/10, Loss: 0.4409\n",
            "Epoch 3/10, Loss: 0.2386\n",
            "Epoch 4/10, Loss: 0.1630\n",
            "Epoch 5/10, Loss: 0.0997\n",
            "Epoch 6/10, Loss: 0.0750\n",
            "Epoch 7/10, Loss: 0.0870\n",
            "Epoch 8/10, Loss: 0.0543\n",
            "Epoch 9/10, Loss: 0.0620\n",
            "Epoch 10/10, Loss: 0.0381\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfRt1QcKK5jN",
        "outputId": "db8c3b3c-4e7e-44bd-f997-5c22ae9f20e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 81.41%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model.eval()  # mode évaluation\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # pas de calcul de gradient\n",
        "    for X_batch, y_batch in val_loader:  # ou test_loader\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        _, preds = torch.max(outputs, 1)  # classe prédite = argmax\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Validation Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
